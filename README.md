# ğŸ‘‹ Hi, I'm Seunggyu Lee

I'm an undergraduate student and researcher at **Korea Aerospace University (KAU)**, majoring in **Aerospace Engineering**.
I currently work as an undergraduate research member in the **Autonomous Systems and Optimization Laboratory (ASOL)**.
My work lies at the intersection of **robotics, autonomy, and language-based reasoning**, where I explore how **large language models (LLMs)** can enhance the **planning and adaptability of autonomous robotic systems**.

---

## ğŸ”¬ Research Interests
- Leveraging **LLMs/VLMs** for reasoning and decision-making in autonomous systems  
- Developing cooperative control strategies for multi-robot systems and human-robot interaction
- **Simulation and optimization** for aerial/ground robotics platforms  

---

## ğŸ§© Projects & Research

### ğŸ¤– On-Device Vision-Language-Model based Robot Behavior Planning Framework
- Led a team of six to design a **VLM-based autonomous robot architecture** deployable on Jetson Orin NX/Nano.  
- Mitigated hallucination via an **LLM-based actorâ€“critic validation loop** and rule-based pre-filter.  
- Implemented **SLAM**, **object detection**, and **ROS 2 Nav2** navigation stack.  
- ğŸ† *Encouragement Award*, 7th National Undergraduate Capstone Design Competition (SASE, 2025).  
- Presentation Poster(Korean):
<img width="442" height="640" alt="Image" src="https://github.com/user-attachments/assets/b4bd2c04-dde0-47bf-b3df-6dd5c73bcf0b" />

<img width="442" height="640" alt="Image" src="https://github.com/user-attachments/assets/2fd8acc8-b2e1-4be8-887b-8961a67de2fd" />

---

### ğŸšœ Multi-UGV Simulation Environment
<img width="531" height="690" alt="Image" src="https://github.com/user-attachments/assets/b27ee485-f346-4f81-8b09-970dd692e38e" />
<img  width="1226" height="392" alt="Image" src="https://github.com/user-attachments/assets/5afbca0b-f971-44a1-bfa8-d44c552157da" />

- Built a simulation environment to evaluate mission allocation algorithms for multiple UGVs.
- Using ROS2 and Gazebo for simulation, with Python for testing and implementation.
- Developed an interactive MATLAB-based GUI to emulate real mission-control usage.

---

### âœˆï¸ Ducted-Fan VTOL Platform
<img width="3234" height="1127" alt="Image" src="https://github.com/user-attachments/assets/4c36484d-0fc5-421b-8fec-2fb4d52ed15d" />

- Designed and validated a **custom ducted-fan VTOL rig** instrumented with high-precision sensors.  
- Developed a **MATLAB + DAQ** pipeline for thrust/torque data acquisition and analysis, achieving 10 cm position accuracy.

---

## ğŸ§  Publication
**Lee, S.**, Oh, S., Jeon, S., Park, Y., Lee, S., Choi, G., & Jang, D.-S. (2024).  
*On-Device Vision Language Model Based Natural Language Mission Execution Framework.*  
IEEE 14th International Conference on Control, Automation and Information Sciences (ICCAIS 2025).

ğŸ“„[Presentation Slides (PDF)](https://github.com/ruga1026/ruga1026/blob/main/SeunggyuLee_ICCAIS2025.pdf)
ğŸ“„ [Paper (PDF)](https://github.com/ruga1026/ruga1026/blob/main/On-Device%20Vision%20Language%20Model%20Based%20Natural%20Language%20Mission%20Execution%20Framework.pdf)
ğŸ¥[Oral presentation at ICCAIS 2025 (YouTube)](https://youtu.be/kwwkg-lqsvA)

---

## ğŸ’» Technical Skills
**Programming:** Python, MATLAB  

**Tools:** ROS2, Gazebo, Linux (Ubuntu), CATIA (3D Modeling)

**Languages:** Korean (Native), English (TOEFL 103)

---

## ğŸ“« Contact
ğŸ“§ ruga1026@gmail.com  
ğŸŒ [GitHub](https://github.com/ruga1026)

---

<!--
> *"Integrating reasoning into autonomy â€” towards robots that understand, plan, and adapt."*



**ruga1026/ruga1026** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
