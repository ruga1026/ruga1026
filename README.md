# ğŸ‘‹ Hi, I'm Seunggyu Lee

I'm an undergraduate researcher at **Korea Aerospace University (KAU)** majoring in **Aerospace Engineering**.  
My work lies at the intersection of **robotics, autonomy, and language-based reasoning**, where I explore how **large language models (LLMs)** can enhance the **planning and adaptability of autonomous robotic systems**.

---

## ğŸ”¬ Research Interests
- Leveraging **LLMs/VLMs** for reasoning and decision-making in autonomous systems  
- **Mission allocation** and cooperative control for multi-UGV teams  
- **Simulation and optimization** for aerial/ground robotics platforms  

---

## ğŸ§© Projects & Research

### ğŸ¤– On-Device Vision-Language-Model based Robot Behavior Planning Framework
- Led a team of six to design a **VLM-based autonomous robot architecture** deployable on Jetson Orin NX/Nano.  
- Mitigated hallucination via an **LLM-based actorâ€“critic validation loop** and rule-based pre-filter.  
- Implemented **SLAM**, **object detection**, and **ROS 2 Nav2** navigation stack.  
- ğŸ† *Encouragement Award*, 7th National Undergraduate Capstone Design Competition (SASE, 2025).  
- Presentation Poster(Korean):
<img width="442" height="640" alt="Image" src="https://github.com/user-attachments/assets/b4bd2c04-dde0-47bf-b3df-6dd5c73bcf0b" />

<img width="442" height="640" alt="Image" src="https://github.com/user-attachments/assets/2fd8acc8-b2e1-4be8-887b-8961a67de2fd" />

---

### ğŸšœ Multi-UGV Simulation Environment
- Built a simulation environment to evaluate mission allocation algorithms for multiple UGVs.  
- Using ROS2 and Gazebo for simulation, with Python for testing and implementation. 

---

### âœˆï¸ Ducted-Fan VTOL Platform
- Designed and validated a **custom ducted-fan VTOL rig** instrumented with high-precision sensors.  
- Developed a **MATLAB + DAQ** pipeline for thrust/torque data acquisition and analysis, achieving 10 cm position accuracy.

---

## ğŸ§  Publication
**Lee, S.**, Oh, S., Jeon, S., Park, Y., Lee, S., Choi, G., & Jang, D.-S. (2024).  
*On-Device Vision Language Model Based Natural Language Mission Execution Framework.*  
IEEE 14th International Conference on Control, Automation and Information Sciences (ICCAIS 2025).

ğŸ“„[Presentation Slides (PDF)](https://github.com/ruga1026/ruga1026/blob/main/SeunggyuLee_ICCAIS2025.pdf)

ğŸ¥[Oral presentation at ICCAIS 2025 (YouTube)](https://youtu.be/kwwkg-lqsvA)

---

## ğŸ’» Technical Skills
**Programming:** Python, MATLAB  

**Tools:** ROS2, Gazebo, Linux (Ubuntu), CATIA (3D Modeling)

**Languages:** Korean (Native), English (TOEFL 103)

---

## ğŸ“« Contact
ğŸ“§ ruga1026@gmail.com  
ğŸŒ [GitHub](https://github.com/ruga1026)

---

<!--
> *"Integrating reasoning into autonomy â€” towards robots that understand, plan, and adapt."*



**ruga1026/ruga1026** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
